\documentclass[mathserif]{beamer}

\usepackage[english]{babel} % language selection: english/ngerman
                            % note: delete all output files on language change
\usepackage[utf8]{inputenc} % allow for using umlauts
\usepackage{lipsum}         % provide lorem ipsum ...
\usepackage{siunitx}        % provide SI units
\usepackage{amsfonts}       % Provides hollow R for real numbers, hollow C for complex numbers, etc.
\usepackage{algorithm}      % Provides Border for Pseudocode
\usepackage{algpseudocode}  % Provides Pseudocode
\usepackage{interval}       % Provides proper intervals
\usepackage{listings}       % Provides Source Code Listing
\usepackage{gensymb}        % Provides the degree symbol
\usepackage{wrapfig}        % Provides wrapping of text around figures
\usepackage{amssymb}        % Provides empty set symbol (\varnothing)
\usepackage{colortbl}
\usepackage{varwidth}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage[export]{adjustbox}
\usepackage{subfig}
\usepackage{tikz}
\usepackage{slashbox}
\usepackage{hyperref}
\usepackage{esvect}
\usepackage[makeroom]{cancel}
\usepackage{pdfpages}
\usepackage{amsmath}
\usepackage{outlines}
\usepackage{kbordermatrix}
\usepackage[customcolors]{hf-tikz}
\usepackage{pgfpages}

\usetikzlibrary{arrows.meta}

\DeclareMathOperator{\Prob}{P}

\tikzset{
    style green/.style={
    set fill color=green!60!lime!40,
    set border color=white,
  },
  style cyan/.style={
    set fill color=cyan!90!blue!60,
    set border color=white,
  },
  style red/.style={
    set fill color=red!30,
    set border color=white,
  },
  style orange/.style={
    set fill color=orange!80!red!40,
    set border color=white,
  },
  hor/.style={
    above left offset={-0.15,0.31},
    below right offset={0.15,-0.10},
    #1
  },
  ver/.style={
    above left offset={-0.10,0.35},
    below right offset={0.10,-0.15},
    #1
  }
}

%\usepackage[T1]{fontenc}
%\usepackage[tt=false,osf]{libertinus}
%\usepackage{inconsolata}

\usetheme[progressbar=frametitle]{metropolis}
%\setbeamertemplate{frame numbering}[fraction]
%\useoutertheme{metropolis}
%\useinnertheme{metropolis}
%\usefonttheme{metropolis}
%\usecolortheme{spruce}
%\setbeamercolor{background canvas}{bg=white}
\metroset{block=fill}

%\setbeamertemplate{note page}[plain]
%\setbeameroption{show notes on second screen=right}

\title{Maßzahlen}
\subtitle{Erwartungswert und Varianz}

\author{Nico Pistel}

\institute[Institute]
{
    Fachbereich Wirtschaft und Informationstechnik\\
    Westfälische Hochschule Bocholt
}

\date{Diskrete Mathematik und Stochastik, 2019}

\subject{Subject}
% This is only inserted into the PDF information catalog. Can be left
% out.

\pgfdeclareimage[height=0.5cm]{university-logo}{img/wh.png}
\logo{\pgfuseimage{university-logo}}

\begin{document}

\begin{frame}[noframenumbering,plain]
    \titlepage
\end{frame}

%\begin{frame}{Outline}
%    \tableofcontents
%    % You might wish to add the option [pausesections]
%\end{frame}

\begin{frame}{Maßzahlen}
    \begin{outline}
        \1 Charakterisieren die Wahrscheinlichkeitsverteilung einer Zufallsvariablen
        \1 Erwartungswert (Mittelwert) $\mu$
        \1 Varianz $\sigma^2$
        \2 Standardabweichung $\sigma$
        \1 Schiefe $\gamma$
        \2 Vgl. Lehrbuch
    \end{outline}
\end{frame}
\section{Erwartungswert}
\begin{frame}{Erwartungswert}
    \begin{outline}
        \1 Erwartungswert einer Zufallsvariablen entspricht dem arithmetischen Mittel einer Häufigkeitsverteilung (deskriptive Statistik)
        \1 Ausprägungen der Zufallsvariablen werden mit ihren Wahrscheinlichkeiten gewichtet und aufsummiert
        \2 Beim arithmetischen Mittel einer Häufigkeitsverteilung geschieht dies mit den relativen Häufigkeiten
    \end{outline}
    \begin{block}{Erwartungswert einer diskreten Zufallsvariablen $X$}
        \[\mathbf{E}(X)=\sum_{x\in X(\Omega)}x\Prob(X=x)\]
    \end{block}
    \begin{block}{Erwartungswert einer stetigen Zufallsvariablen $X$}
        \[\mathbf{E}(X)=\int_{-\infty}^{\infty}xf(x)dx\]
    \end{block}
\end{frame}
\begin{frame}{Erwartungswert}
    \begin{outline}
        \1 Der Erwartungswert ist der Wert, den die Zufallsvariable $X$ im Durchschnitt annehmen wird
        \2 Bei häufiger Wiederholung des Zufallsexperiments
        \1 Der Erwartungswert kann bei diskreten Zufallsvariablen Werte annehmen, die nicht im Wertebereich von $X$ enthalten sind
        \2 Er kann zwischen den Realisationen liegen
        \2 Vgl. fairer Würfel
    \end{outline}
    \begin{block}{Erwartungswert einer (um $c$) symmetrischen Verteilung}
        \[\forall a:f(c+a)=f(c-a)\Longrightarrow\mathbf{E}(X)=c\]
    \end{block}
\end{frame}

\section{Mathematische Erwartung}
\begin{frame}{Mathematische Erwartung}
    \begin{outline}
        \1 Durch Komposition von $X$ mit einer reellen Funktion $g:\mathbb{R}\rightarrow\mathbb{R}$ lässt sich eine neue Zufallsvariable $Y\coloneqq g(X)$ definieren
        \2 $\Omega\ni\omega\xmapsto{X(\cdot)}x\xmapsto{g(\cdot)}y=g(X(\omega))$
        \1 $\mathbf{E}(Y)=\mathbf{E}(g(X))$ wird dann als \textit{mathematische Erwartung} bezeichnet
    \end{outline}
    \begin{block}{Mathematische Erwartung für diskrete Zufallsvariablen $X$}
        \[\mathbf{E}(Y)=\mathbf{E}(g(X))=\sum_{x\in X(\Omega)}g(x)\Prob(X=x)\]
    \end{block}
    \begin{block}{Mathematische Erwartung für stetige Zufallsvariablen $X$}
        \[\mathbf{E}(Y)=\mathbf{E}(g(X))=\int_{-\infty}^{\infty}g(x)f(x)dx\]
    \end{block}
\end{frame}
\begin{frame}{Rechenregeln für den Erwartungswert}
    \begin{outline}
        \1 Für Zufallsvariable $X$, Konstanten $a,b,c\in\mathbb{R}$ und reelle Funktionen $g,h:\mathbb{R}\rightarrow\mathbb{R}$ gelten folgende Rechenregeln
        \1 $\mathbf{E}(c)=c$
        \1 \[\begin{rcases}
            \mathbf{E}(bX)=b\mathbf{E}(X)\\
            \mathbf{E}(a+X)=a+\mathbf{E}(X)
        \end{rcases} \mathbf{E}(a+bX)=a+b\mathbf{E}(X)\]
        \1 $\mathbf{E}\Big(g(X)+h(X)\Big)=\mathbf{E}\Big(g(X)\Big)+\mathbf{E}\Big(h(X)\Big)$
    \end{outline}
\end{frame}
\begin{frame}{Rechenregeln für den Erwartungswert}
    \begin{outline}
        \1 Für (nicht notwendigermaßen stochastisch unabhängige) Zufallsvariablen $X,Y:\Omega\longrightarrow\mathbb{R}$ gilt:\begin{align*}
            \mathbf{E}(X+Y)&=\sum_{\omega\in\Omega}(X+Y)(\omega)\Prob(\{\omega\})\\
            &=\sum_{\omega\in\Omega}\Big(X(\omega)+Y(\omega)\Big)\Prob(\{\omega\})\\
            &=\sum_{\omega\in\Omega}X(\omega)\Prob(\{\omega\})+Y(\omega)\Prob(\{\omega\})\\
            &=\underbrace{\sum_{\omega\in\Omega}X(\omega)\Prob(\{\omega\})}+\underbrace{\sum_{\omega\in\Omega}Y(\omega)\Prob(\{\omega\})}\\
            &=\;\;\;\;\;\;\;\;\;\mathbf{E}(X)\;\;\;\;\;\;\;\:\:+\;\;\;\;\;\;\;\:\:\mathbf{E}(Y)
        \end{align*}
    \end{outline}
\end{frame}
\begin{frame}{Rechenregeln für den Erwartungswert}
    \begin{outline}
        \1 Für \textbf{stochastisch unabhängige} Zufallsvariablen $X,Y:\Omega\longrightarrow\mathbb{R}$ gilt:\begin{align*}
            \mathbf{E}(X\cdot Y)&=\sum_{x\in X(\Omega)}\sum_{y\in Y(\Omega)}xy\Prob(X=x\cap Y=y)\\
            &=\sum_{x\in X(\Omega)}\sum_{y\in Y(\Omega)}xy\Prob(X=x)\Prob(Y=y)\\
            &=\sum_{x\in X(\Omega)}\Big(x\Prob(X=x)\underbrace{\sum_{y\in Y(\Omega)}y\Prob(Y=y)}_{const.\text{ bzgl. }x}\Big)\\
            &=\left(\sum_{y\in Y(\Omega)}y\Prob(Y=y)\right)\cdot\left(\sum_{x\in X(\Omega)}x\Prob(X=x)\right)\\
            &=\mathbf{E}(Y)\cdot\mathbf{E}(X)=\mathbf{E}(X)\cdot\mathbf{E}(Y)
        \end{align*}
    \end{outline}
\end{frame}

\section{Varianz}
\begin{frame}{Varianz}
    \begin{outline}
        \1 Varianz einer Zufallsvariablen ist Maß für die Streuung um den Erwartungswert
        \1 Quadratische Abweichungen der Ausprägungen der Zufallsvariablen zum Erwartungswert werden mit ihren Wahrscheinlichkeiten gewichtet und aufsummiert
    \end{outline}
    \begin{block}{Varianz einer diskreten Zufallsvariable $X$}
        \[\mathbf{Var}(X)=\sum_{x\in X(\Omega)}\Big(\mathbf{E}(X)-x\Big)^2\Prob(X=x)\]
    \end{block}
    \begin{block}{Varianz einer stetigen Zufallsvariable $X$}
        \[\mathbf{Var}(X)=\int_{-\infty}^{\infty}\Big(\mathbf{E}(X)-x\Big)^2f(x)dx\]
    \end{block}
\end{frame}
\begin{frame}{Varianz}
    \begin{outline}
        \1 Varianz einer Zufallsvariable $X$ entspricht dem Erwartungswert der Zufallsvariable $Z=(\mu-X)^2$ mit $\mu=\mathbf{E}(X)$:\begin{align*}
            \mathbf{E}(Z)&=\mathbf{E}\Big((\mu-X)^2\Big)\\
            &=\sum_{x\in X(\Omega)}(\mu-x)^2\Prob(X=x)\\
            &=\sum_{x\in X(\Omega)}\Big(\mathbf{E}(X)-x\Big)^2\Prob(X=x)\\
            &\eqqcolon\mathbf{Var}(X)
        \end{align*}
    \end{outline}
\end{frame}
\begin{frame}{Varianz}
    \begin{outline}
        \1 Die Varianz wird auch mit $\sigma^2$ bezeichnet
        \1 Die Quadratwurzel der Varianz $\sqrt{\sigma^2}=\sigma$ heißt Standardabweichung
        \1 Die Varianz ist nicht-negativ $\sigma^2\geq0$
        \2 Ist der Wert der Zufallsvariablen $X$ nicht konstant, so ist die Varianz sogar stets positiv $\sigma^2>0$
    \end{outline}
\end{frame}
\begin{frame}{Rechenregeln für die Varianz}
    \begin{outline}
        \1 Mit der Definition der Varianz bezüglich des Erwartungswertes der quadrierten Abweichungen folgt der \textbf{Verschiebungssatz}\begin{align*}
            \mathbf{Var}(X)&=\mathbf{E}\Big((X-\mu)^2\Big)\\
            &=\mathbf{E}\Big(X^2-2\mu X+\mu^2\Big)\\
            &=\mathbf{E}(X^2)+\mathbf{E}(-2\mu X)+\mathbf{E}(\mu^2)\\
            &=\mathbf{E}(X^2)-2\mu\underbrace{\mathbf{E}(X)}_{=\mu}+\mu^2\\
            &=\mathbf{E}(X^2)-2\mu^2+\mu^2\\
            &=\mathbf{E}(X^2)-\mu^2\\
            &=\mathbf{E}(X^2)-\Big(\mathbf{E}(X)\Big)^2
        \end{align*}
    \end{outline}
\end{frame}
\begin{frame}{Rechenregeln für die Varianz}
    \begin{outline}
        \1 Die Varianz ist invariant gegenüber Nullpunktverschiebungen
        \1 Eine lineare Transformation der Zufallsvariable wirkt sich folgendermaßen auf die Varianz aus:\begin{align*}
            \mathbf{Var}(a+bX)&=\mathbf{E}\Big((a+bX)^2\Big)-\Big(\mathbf{E}(a+bX)\Big)^2\\
            &=\mathbf{E}\Big(a^2+2abX+b^2X^2\Big)-\Big(a+b\mu\Big)^2\\
            &=a^2+2ab\mu+b^2\mathbf{E}(X^2)-\Big(a^2+2ab\mu+b^2\mu^2\Big)\\
            &=a^2+2ab\mu+b^2\mathbf{E}(X^2)-a^2-2ab\mu-b^2\mu^2\\
            &=b^2\mathbf{E}(X^2)-b^2\mu^2\\
            &=b^2\underbrace{\Big(\mathbf{E}(X^2)-\mu^2\Big)}_{=\mathbf{Var}(X)}\\
            &=b^2\mathbf{Var}(X)
        \end{align*}
    \end{outline}
\end{frame}

\end{document}